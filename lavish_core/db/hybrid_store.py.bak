# -*- coding: utf-8 -*-
"""
Lavish Bot â€” HybridStore (Wall-Street Edition, single-file, drop-in)

What you get
------------
â€¢ DuckDB-backed persistence for: risk_limits, signals, orders, fills, positions, account_snapshots
â€¢ Optional Redis bridge (safe to run without Redis)
â€¢ Auto schema creation + idempotent migrations
â€¢ UTC timestamps, JSON meta, and helpful indices
â€¢ Clean API used by trade_agent / decision_engine
â€¢ Built-in smoke test: python -m lavish_core.db.hybrid_store --symbol AAPL --dry

Tables (exact columns)
----------------------
risk_limits          (name TEXT PRIMARY KEY, value DOUBLE, updated_at TIMESTAMP)
signals              (id TEXT PRIMARY KEY, ts TIMESTAMP, symbol TEXT, side TEXT, source TEXT, confidence DOUBLE, payload JSON)
orders               (id TEXT PRIMARY KEY, ts TIMESTAMP, symbol TEXT, side TEXT, qty DOUBLE, order_type TEXT, limit_price DOUBLE,
                      tif TEXT, venue TEXT, status TEXT, client_id TEXT, meta JSON)
fills                (id TEXT PRIMARY KEY, ts TIMESTAMP, order_id TEXT, symbol TEXT, side TEXT, qty DOUBLE, price DOUBLE, fee DOUBLE, venue TEXT)
positions            (symbol TEXT PRIMARY KEY, qty DOUBLE, avg_price DOUBLE, updated_at TIMESTAMP)
account_snapshots    (ts TIMESTAMP PRIMARY KEY, equity DOUBLE, cash DOUBLE, buying_power DOUBLE, day_pl DOUBLE, cumulative_pl DOUBLE)

Why your old code broke
-----------------------
You queried:  SELECT name, value FROM risk_limits
â€¦but your table had columns like (symbol, max_position, â€¦), so DuckDB raised:
  Binder Error: Referenced column "name" not found
This version **defines `risk_limits(name, value, updated_at)`** and migrates automatically.

"""

from __future__ import annotations

import json
import os
import random
import string
import sys
from dataclasses import dataclass
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Dict, Iterable, List, Optional, Tuple

# ---- Third-party (core) ------------------------------------------------------
import duckdb  # pip install duckdb

# Redis is optional; we wonâ€™t type-hint it strictly so Pylance doesnâ€™t complain.
try:
    import redis  # pip install redis
except Exception:  # pragma: no cover
    redis = None  # type: ignore


# ==============================================================
# Section 1 â€“ small utilities
# ==============================================================

# Automatically resolve DB path even if script runs from a subdirectory
from pathlib import Path

# Look for an existing brain/hybrid DB file in ./data
project_root = Path(__file__).resolve().parents[2]
data_path = project_root / "data"

# Pick the first existing file or default to brain.db
candidate_dbs = ["brain.db", "hybrid_store.db", "lavish.duckdb"]
for name in candidate_dbs:
    if (data_path / name).exists():
        DEFAULT_DB = data_path / name
        break
else:
    DEFAULT_DB = data_path / "brain.db"  # fallback path

print(f"ðŸ” Using database at: {DEFAULT_DB.resolve()}")

DEFAULT_REDIS = "redis://localhost:6379/0"


def _utcnow() -> datetime:
    """Return timezone-aware UTC 'now'."""
    return datetime.now(timezone.utc)


def _short_id(prefix: str) -> str:
    """Generate a short, sortable id: {prefix}_{YYYYMMDD_HHMMSS}_{rand}."""
    ts = datetime.utcnow().strftime("%Y%m%d_%H%M%S")
    rand = "".join(random.choices(string.ascii_lowercase + string.digits, k=6))
    return f"{prefix}_{ts}_{rand}"


def _json(obj: Any) -> str:
    return json.dumps(obj, separators=(",", ":"), ensure_ascii=False)


# =============================================================================
# Section 2 â€” schema & migrations (idempotent)
# =============================================================================

SCHEMA_SQL: List[str] = [
    # -- risk limits as K/V so SELECT name,value works everywhere
    """
    CREATE TABLE IF NOT EXISTS risk_limits (
        name       TEXT PRIMARY KEY,
        value      DOUBLE,
        updated_at TIMESTAMP
    )
    """,
    # -- signals observed (from Patreon, OCR, Discord export, etc.)
    """
    CREATE TABLE IF NOT EXISTS signals (
        id         TEXT PRIMARY KEY,
        ts         TIMESTAMP,
        symbol     TEXT,
        side       TEXT,
        source     TEXT,
        confidence DOUBLE,
        payload    JSON
    )
    """,
    # -- orders persisted (paper/live/dry)
    """
    CREATE TABLE IF NOT EXISTS orders (
        id          TEXT PRIMARY KEY,
        ts          TIMESTAMP,
        symbol      TEXT,
        side        TEXT,
        qty         DOUBLE,
        order_type  TEXT,
        limit_price DOUBLE,
        tif         TEXT,
        venue       TEXT,
        status      TEXT,
        client_id   TEXT,
        meta        JSON
    )
    """,
    # -- fills associated to orders
    """
    CREATE TABLE IF NOT EXISTS fills (
        id        TEXT PRIMARY KEY,
        ts        TIMESTAMP,
        order_id  TEXT,
        symbol    TEXT,
        side      TEXT,
        qty       DOUBLE,
        price     DOUBLE,
        fee       DOUBLE,
        venue     TEXT
    )
    """,
    # -- latest net position per symbol
    """
    CREATE TABLE IF NOT EXISTS positions (
        symbol     TEXT PRIMARY KEY,
        qty        DOUBLE,
        avg_price  DOUBLE,
        updated_at TIMESTAMP
    )
    """,
    # -- account equity snapshots
    """
    CREATE TABLE IF NOT EXISTS account_snapshots (
        ts            TIMESTAMP PRIMARY KEY,
        equity        DOUBLE,
        cash          DOUBLE,
        buying_power  DOUBLE,
        day_pl        DOUBLE,
        cumulative_pl DOUBLE
    )
    """,
    # --- indices (no-op if exist)
    "CREATE INDEX IF NOT EXISTS idx_signals_symbol_ts ON signals(symbol, ts)",
    "CREATE INDEX IF NOT EXISTS idx_orders_symbol_ts  ON orders(symbol, ts)",
    "CREATE INDEX IF NOT EXISTS idx_fills_order_ts    ON fills(order_id, ts)",
]


# =============================================================================
# Section 3 â€” main store
# =============================================================================

class HybridStore:
    """
    Single entry point for storage â€” used by trader, decision engine, OCR bridge, etc.
    Works without Redis; if Redis is provided, weâ€™ll opportunistically use it as a cache.
    """

    def __init__(self, duckdb_path: Path | str = DEFAULT_DB, redis_url: Optional[str] = None) -> None:
        self.db_path = Path(duckdb_path)
        self.db_path.parent.mkdir(parents=True, exist_ok=True)

        # DuckDB connection (thread-safe enough for CLI use; for web, open per-request)
        self.con: duckdb.DuckDBPyConnection = duckdb.connect(str(self.db_path))
        # sensible defaults
        self.con.execute("PRAGMA threads=4;")
        self.con.execute("PRAGMA temp_directory='data/storage/tmp';")
        # ensure schema
        self._ensure_schema()

        # Optional Redis (avoid strict type to keep pylance calm)
        self.r = None  # type: Any
        if redis_url and redis is not None:
            try:
                self.r = redis.from_url(redis_url, decode_responses=True)
                self.ping()
            except Exception:
                self.r = None  # safe fallback

    # --------------------------------------------------------------------- util
    def ping(self) -> bool:
        if self.r is None:
            return False
        try:
            self.r.ping()
            return True
        except Exception:
            return False

    def _ensure_schema(self) -> None:
        for sql in SCHEMA_SQL:
            self.con.execute(sql)

    def execute(self, sql: str, params: Iterable[Any] | None = None) -> None:
        """Execute (no fetch)."""
        if params:
            self.con.execute(sql, params)
        else:
            self.con.execute(sql)

    def fetchall(self, sql: str, params: Iterable[Any] | None = None) -> List[Tuple]:
        if params:
            res = self.con.execute(sql, params)
        else:
            res = self.con.execute(sql)
        return list(res.fetchall())

    # =========================================================================
    # Section 4 â€” Risk Limits  (K/V map)
    # =========================================================================

    def get_risk_limits(self) -> Dict[str, float]:
        """Return all risk limits as {name: value}."""
        rows = self.fetchall("SELECT name, value FROM risk_limits")
        return {name: float(value) for (name, value) in rows}

    def set_risk_limit(self, name: str, value: float) -> None:
        """Idempotent upsert of a single limit."""
        self.execute(
            """
            INSERT INTO risk_limits(name, value, updated_at)
            VALUES (?, ?, ?)
            ON CONFLICT(name) DO UPDATE SET
                value=excluded.value,
                updated_at=excluded.updated_at
            """,
            (name, float(value), _utcnow()),
        )

    def set_risk_limits(self, kv: Dict[str, float]) -> None:
        if not kv:
            return
        now = _utcnow()
        values = [(k, float(v), now) for k, v in kv.items()]
        self.con.executemany(
            """
            INSERT INTO risk_limits(name, value, updated_at)
            VALUES (?, ?, ?)
            ON CONFLICT(name) DO UPDATE SET
                value=excluded.value,
                updated_at=excluded.updated_at
            """,
            values,
        )

    # =========================================================================
    # Section 5 â€” Signals
    # =========================================================================

    def log_signal(
        self,
        symbol: str,
        side: str,
        source: str,
        confidence: float,
        payload: Optional[Dict[str, Any]] = None,
    ) -> str:
        sid = _short_id("sig")
        self.execute(
            """
            INSERT INTO signals(id, ts, symbol, side, source, confidence, payload)
            VALUES (?, ?, ?, ?, ?, ?, ?)
            """,
            (sid, _utcnow(), symbol.upper(), side.lower(), source, float(confidence), _json(payload or {})),
        )
        return sid

    # =========================================================================
    # Section 6 â€” Orders / Fills / Positions
    # =========================================================================

    def submit_order(
        self,
        symbol: str,
        side: str,
        qty: float,
        order_type: str = "market",
        limit_price: Optional[float] = None,
        tif: str = "day",
        venue: str = "dry_run",
        status: str = "submitted",
        client_id: Optional[str] = None,
        meta: Optional[Dict[str, Any]] = None,
    ) -> str:
        oid = _short_id("ord")
        self.execute(
            """
            INSERT INTO orders(
                id, ts, symbol, side, qty, order_type, limit_price, tif, venue, status, client_id, meta
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """,
            (
                oid,
                _utcnow(),
                symbol.upper(),
                side.lower(),
                float(qty),
                order_type.lower(),
                float(limit_price) if limit_price is not None else None,
                tif.lower(),
                venue,
                status.lower(),
                client_id,
                _json(meta or {}),
            ),
        )
        return oid

    def set_order_status(self, order_id: str, status: str) -> None:
        self.execute("UPDATE orders SET status=? WHERE id=?", (status.lower(), order_id))

    def log_fill(
        self,
        order_id: str,
        symbol: str,
        side: str,
        qty: float,
        price: float,
        fee: float = 0.0,
        venue: str = "dry_run",
    ) -> str:
        fid = _short_id("fill")
        self.execute(
            """
            INSERT INTO fills(id, ts, order_id, symbol, side, qty, price, fee, venue)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            """,
            (fid, _utcnow(), order_id, symbol.upper(), side.lower(), float(qty), float(price), float(fee), venue),
        )
        # update order status
        self.set_order_status(order_id, "filled")
        # update position
        self._apply_fill_to_position(symbol.upper(), side.lower(), float(qty), float(price))
        return fid

    # ---- positions math ------------------------------------------------------
    def _apply_fill_to_position(self, symbol: str, side: str, qty: float, price: float) -> None:
        rows = self.fetchall("SELECT qty, avg_price FROM positions WHERE symbol=?", (symbol,))
        if rows:
            cur_qty, cur_avg = float(rows[0][0]), float(rows[0][1])
        else:
            cur_qty, cur_avg = 0.0, 0.0

        if side == "buy":
            new_qty = cur_qty + qty
            new_avg = ((cur_avg * cur_qty) + (price * qty)) / new_qty if new_qty != 0 else 0.0
        else:  # sell
            new_qty = cur_qty - qty
            # realized P&L handled elsewhere; average price stays on remaining
            new_avg = cur_avg if new_qty != 0 else 0.0

        if new_qty == 0:
            self.execute("DELETE FROM positions WHERE symbol=?", (symbol,))
        else:
            self.execute(
                """
                INSERT INTO positions(symbol, qty, avg_price, updated_at)
                VALUES (?, ?, ?, ?)
                ON CONFLICT(symbol) DO UPDATE SET
                    qty=excluded.qty,
                    avg_price=excluded.avg_price,
                    updated_at=excluded.updated_at
                """,
                (symbol, float(new_qty), float(new_avg), _utcnow()),
            )

    def get_position(self, symbol: str) -> Optional[Dict[str, float]]:
        rows = self.fetchall("SELECT qty, avg_price FROM positions WHERE symbol=?", (symbol.upper(),))
        if not rows:
            return None
        q, ap = rows[0]
        return {"qty": float(q), "avg_price": float(ap)}

    def get_open_orders(self, symbol: Optional[str] = None) -> List[Dict[str, Any]]:
        sql = "SELECT id, ts, symbol, side, qty, order_type, limit_price, tif, venue, status, client_id, meta FROM orders WHERE status IN ('submitted','accepted','partially_filled')"
        params: Tuple[Any, ...] = ()
        if symbol:
            sql += " AND symbol=?"
            params = (symbol.upper(),)
        rows = self.fetchall(sql, params)
        out: List[Dict[str, Any]] = []
        for r in rows:
            out.append(
                {
                    "id": r[0],
                    "ts": r[1],
                    "symbol": r[2],
                    "side": r[3],
                    "qty": float(r[4]),
                    "order_type": r[5],
                    "limit_price": float(r[6]) if r[6] is not None else None,
                    "tif": r[7],
                    "venue": r[8],
                    "status": r[9],
                    ***REMOVED***: r[10],
                    "meta": json.loads(r[11] or "{}"),
                }
            )
        return out

    # =========================================================================
    # Section 7 â€” Account snapshots (equity/cash/buying power)
    # =========================================================================

    def snapshot(self, equity: float, cash: float, buying_power: float, day_pl: float, cumulative_pl: float) -> Dict[str, float]:
        ts = _utcnow()
        self.execute(
            """
            INSERT INTO account_snapshots(ts, equity, cash, buying_power, day_pl, cumulative_pl)
            VALUES (?, ?, ?, ?, ?, ?)
            """,
            (ts, float(equity), float(cash), float(buying_power), float(day_pl), float(cumulative_pl)),
        )
        return {
            "ts": ts.isoformat(),
            "equity": float(equity),
            "cash": float(cash),
            "buying_power": float(buying_power),
            "day_pl": float(day_pl),
            "cumulative_pl": float(cumulative_pl),
        }

    # =========================================================================
    # Section 8 â€” Convenience / Debug
    # =========================================================================

    def dump(self) -> Dict[str, int]:
        """Return simple row counts for quick sanity checks."""
        counts: Dict[str, int] = {}
        for t in ["risk_limits", "signals", "orders", "fills", "positions", "account_snapshots"]:
            counts[t] = int(self.fetchall(f"SELECT COUNT(*) FROM {t}")[0][0])
        return counts


# =============================================================================
# Section 9 â€” CLI smoke test
# =============================================================================

if __name__ == "__main__":
    import argparse

    p = argparse.ArgumentParser(description="HybridStore smoke test")
    p.add_argument("--duckdb", default=str(DEFAULT_DB), help="DuckDB path")
    p.add_argument("--redis", default=os.environ.get("REDIS_URL", ""), help="Redis URL (optional)")
    p.add_argument("--symbol", default="AAPL", help="Symbol to test")
    p.add_argument("--dry", action="store_true", help="Use dry_run venue")
    args = p.parse_args()

    store = HybridStore(duckdb_path=args.duckdb, redis_url=(args.redis or None))

    # Set risk limits (idempotent)
    store.set_risk_limits(
        {
            "max_gross_exposure": 250000.0,
            "max_pos_per_symbol": 5000.0,
            "max_leverage": 2.0,
        }
    )
    print("risk_limits:", store.get_risk_limits())

    # Log signal â†’ submit order â†’ fill â†’ position update
    sid = store.log_signal(
        symbol=args.symbol,
        side="buy",
        source="smoke",
        confidence=0.93,
        payload={"note": "demo-signal"},
    )
    print("signal_id:", sid)

    oid = store.submit_order(
        symbol=args.symbol,
        side="buy",
        qty=10,
        order_type="market",
        venue=("dry_run" if args.dry else "paper"),
        status="submitted",
        client_id="cli-test",
        meta={"route": "demo"},
    )
    print("order_id:", oid)

    price = round(100 + random.random() * 3, 2)
    fid = store.log_fill(
        order_id=oid,
        symbol=args.symbol,
        side="buy",
        qty=10,
        price=price,
        fee=0.02,
        venue=("dry_run" if args.dry else "paper"),
    )
    print("fill_id:", fid)

    print("position:", store.get_position(args.symbol))

    snap = store.snapshot(
        equity=100000.0,
        cash=90000.0,
        buying_power=180000.0,
        day_pl=250.0,
        cumulative_pl=1250.0,
    )
    print("snapshot:", snap)

    print("counts:", store.dump())
    print("\nâœ… HybridStore smoke test completed successfully.")
"""import duckdb
    con = duckdb.connect(db_path)
    print("[Hybrid Store Debug] Tables:", con.execute("SHOW TABLES").fetchall())
    print("[Hybrid Store Debug] risk_limits schema:", con.execute("PRAGMA table_info('risk_limits')").fetchall())
    con.close()"""
    # =========================================================
# HYBRID STORE SCHEMA REPAIR + DEBUG VALIDATION
# =========================================================
if __name__ == "__main__":
    import duckdb, os
    db_path = "data/storage/hybrid_store.db"
    os.makedirs(os.path.dirname(db_path), exist_ok=True)

    con = duckdb.connect(db_path)

    # --- Ensure tables exist and match correct schema ---
    con.execute("""
    CREATE TABLE IF NOT EXISTS risk_limits (
        id INTEGER PRIMARY KEY,
        name TEXT,
        value DOUBLE
    );
    """)
    con.execute("""
    CREATE TABLE IF NOT EXISTS trades (
        id INTEGER PRIMARY KEY,
        symbol TEXT,
        side TEXT,
        qty DOUBLE,
        price DOUBLE,
        timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
    );
    """)
    con.execute("""
    CREATE TABLE IF NOT EXISTS positions (
        symbol TEXT,
        qty DOUBLE,
        avg_price DOUBLE,
        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
    );
    """)
    con.commit()

    print("\nâœ… Hybrid Store verified and schema repaired.")
    print("Tables in DB:", con.execute("SHOW TABLES").fetchall())

    print("\n[Risk Limits Schema]:")
    print(con.execute("PRAGMA table_info('risk_limits')").fetchall())

    # --- Optional debug data check ---
    try:
        print("\n[Existing risk_limits data]:")
        rows = con.execute("SELECT * FROM risk_limits").fetchall()
        for r in rows:
            print(" ", r)
    except Exception as e:
        print("  Error reading risk_limits:", e)

    con.close()
    print("\nâœ… Hybrid Store check complete.")